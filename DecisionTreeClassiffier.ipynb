{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize node class\n",
    "class Node:\n",
    "    \n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.feature_index = 0\n",
    "        self.threshold = 0\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.name = -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement a decision tree classifier\n",
    "class MyDecisionTreeClassifier:\n",
    "    \n",
    "    def __init__(self, max_depth, features):\n",
    "        self.max_depth = max_depth\n",
    "        self.root = None\n",
    "        self.features = features\n",
    "    \n",
    "    def gini(self, group):\n",
    "        '''\n",
    "        A Gini score gives an idea of how good a split is by how mixed the\n",
    "        classes are in the two groups created by the split.\n",
    "        \n",
    "        A perfect separation results in a Gini score of 0,\n",
    "        whereas the worst case split that results in 50/50\n",
    "        classes in each group result in a Gini score of 0.5\n",
    "        (for a 2 class problem).\n",
    "        '''\n",
    "        if len(group) == 0:\n",
    "            return 1\n",
    "        gini = 1\n",
    "        for clas in [i for i in range(self.features)]:\n",
    "            gini -= (group.count(clas)/len(group))**2\n",
    "        return round(gini, 4)\n",
    "    \n",
    "    def split_data(self, X, y) -> tuple[int, int]:\n",
    "        \n",
    "        # test all the possible splits in O(N*F) where N in number of samples\n",
    "        # and F is number of features\n",
    "\n",
    "        index = -1\n",
    "        threshhold = -1\n",
    "        best_ig = float('inf')\n",
    "\n",
    "        # iterate over every threshold in dataset\n",
    "        for i in range(X.shape[0]):\n",
    "            for j in range(X.shape[1]):\n",
    "                group1 = [y[k] for k, elem in enumerate(X[:,j]) if elem <= X[i,j]]\n",
    "                group2 = [y[k] for k, elem in enumerate(X[:,j]) if elem > X[i,j]]\n",
    "                gini1 = self.gini(group1)\n",
    "                gini2 = self.gini(group2)\n",
    "\n",
    "                # relative ig, because root gini is constant\n",
    "                ig = (len(group1)/len(y))*gini1 + (len(group2)/len(y))*gini2\n",
    "                if ig < best_ig:\n",
    "                    best_ig = ig\n",
    "                    threshhold = X[i,j]\n",
    "                    index = j\n",
    "        \n",
    "        return (index, threshhold)\n",
    "    \n",
    "    def build_tree(self, X, y, depth = 0):\n",
    "\n",
    "        # at first we set three indicators when our tree should stop building itself (exit recursion)\n",
    "        if list(y) == []:\n",
    "            return None\n",
    "        if len(set(y)) == 1:\n",
    "            leaf = Node(X, y)\n",
    "            leaf.right = None\n",
    "            leaf.left = None\n",
    "            leaf.name = -1\n",
    "            for elem in set(list(y)):\n",
    "                if list(y).count(elem) > list(y).count(leaf.name):\n",
    "                    leaf.name = elem \n",
    "            return leaf\n",
    "        if depth == self.max_depth:\n",
    "            leaf = Node(X, y)\n",
    "            leaf.right = None\n",
    "            leaf.left = None\n",
    "            leaf.name = -1\n",
    "            for elem in set(list(y)):\n",
    "                if list(y).count(elem) > list(y).count(leaf.name):\n",
    "                    leaf.name = elem \n",
    "            return leaf\n",
    "        \n",
    "        # now we create a root node\n",
    "        root = Node(X, y)\n",
    "        for elem in set(list(y)):\n",
    "                if list(y).count(elem) > list(y).count(root.name):\n",
    "                    root.name = elem \n",
    "        split = self.split_data(X, y)\n",
    "        root.feature_index = split[0]\n",
    "        root.threshold = split[1]\n",
    "\n",
    "        # based on split we calculate data for right and left child\n",
    "        y_left = np.array([y[k] for k, elem in enumerate(X[:,root.feature_index]) if elem <= root.threshold])\n",
    "        y_right = np.array([y[k] for k, elem in enumerate(X[:,root.feature_index]) if elem > root.threshold])\n",
    "        X_left = np.array([X[k] for k, elem in enumerate(X[:,root.feature_index]) if elem <= root.threshold])\n",
    "        X_right = np.array([X[k] for k, elem in enumerate(X[:,root.feature_index]) if elem > root.threshold])\n",
    "\n",
    "        # recursively make a tree\n",
    "        root.left = self.build_tree(X_left, y_left, depth+1)\n",
    "        root.right = self.build_tree(X_right, y_right, depth+1)\n",
    "        return root\n",
    "\n",
    "        \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # basically wrapper for build tree / train\n",
    "        self.root = self.build_tree(X,y)\n",
    "        return 0\n",
    "\n",
    "    def predict(self, root, X_test):\n",
    "        \n",
    "        # traverse the tree while there is a child\n",
    "        # and return the predicted class for it, \n",
    "        if X_test[root.feature_index] > root.threshold:\n",
    "            if root.right != None:\n",
    "                return self.predict(root.right, X_test)\n",
    "            return root.name\n",
    "        if X_test[root.feature_index] <= root.threshold:\n",
    "            if root.left != None:\n",
    "                return self.predict(root.left, X_test)\n",
    "            return root.name\n",
    "        \n",
    "    def evaluate(self, X_test, y_test):\n",
    "        # evaluate success rate\n",
    "        plus = 0\n",
    "        for i, x in enumerate(list(X_test)):\n",
    "            if self.predict(self.root, x) == y_test[i]:\n",
    "                plus += 1\n",
    "        return f'{round((plus/len(X_test))*100, 2)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "breast = load_breast_cancer()\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.54%\n"
     ]
    }
   ],
   "source": [
    "treee = MyDecisionTreeClassifier(6,2)\n",
    "X, y = breast.data, breast.target\n",
    "\n",
    "# build a tree 10 times and print avarage success rate for breast cancer dataset\n",
    "\n",
    "sum = 0\n",
    "for _ in range(10):\n",
    "    X, y = shuffle(X, y, random_state=random.randint(0, 10000000))\n",
    "    train_X = X[:int(round(len(X)*0.8))]\n",
    "    train_y = y[:int(round(len(X)*0.8))]\n",
    "    test_X = X[int(round(len(X)*0.8)):]\n",
    "    test_y = y[int(round(len(X)*0.8)):]\n",
    "    treee.fit(train_X, train_y)\n",
    "    sum += float(treee.evaluate(test_X, test_y))\n",
    "\n",
    "print(f'{round(sum/10, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.07%\n"
     ]
    }
   ],
   "source": [
    "treee = MyDecisionTreeClassifier(6, 3)\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# build a tree 50 times and print avarage success rate for iris dataset\n",
    "\n",
    "sum = 0\n",
    "for _ in range(50):\n",
    "    X, y = shuffle(X, y, random_state=random.randint(0, 10000000))\n",
    "    train_X = X[:int(round(len(X)*0.8))]\n",
    "    train_y = y[:int(round(len(X)*0.8))]\n",
    "    test_X = X[int(round(len(X)*0.8)):]\n",
    "    test_y = y[int(round(len(X)*0.8)):]\n",
    "    treee.fit(train_X, train_y)\n",
    "    sum += float(treee.evaluate(test_X, test_y))\n",
    "\n",
    "print(f'{round(sum/50, 2)}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
